{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics,preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "# Imports for PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For full dataset, run tran_feature_selection notebook before this one\n",
    "# For small subset of data, run tran_sample_preprocessing notebook beofore this one (ideal for testing model on CPU)\n",
    "\n",
    "%store -r benign_flows  \n",
    "%store -r mixed_flows\n",
    "%store -r features\n",
    "\n",
    "dim = len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.85338091401729e-16, 0.9999999999999999)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = benign_flows.loc[:, features].values\n",
    "x = StandardScaler().fit_transform(x) # normalizing the features\n",
    "np.mean(x),np.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the top k components whose cumulative variance exceeds 95%\n",
    "  \n",
    "pca = PCA(0.95)\n",
    "pca.fit(x)\n",
    "top_k_component = pca.n_components_\n",
    "top_k_component\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-run PCA with only top k features again\n",
    "top_k_features = features[:top_k_component]\n",
    "\n",
    "top_k_x = benign_flows.loc[:, top_k_features].values\n",
    "top_k_x = StandardScaler().fit_transform(top_k_x) # normalizing the features\n",
    "np.mean(top_k_x),np.std(top_k_x)\n",
    "\n",
    "top_k_pca = PCA(n_components=top_k_component-1)   \n",
    "top_k_principalComponents = top_k_pca.fit_transform(top_k_x)\n",
    "\n",
    "top_k_var=np.cumsum(np.round(top_k_pca.explained_variance_ratio_, decimals=3)*100)\n",
    "# print(top_k_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse mapping of low dimensional to original coordinate space\n",
    "data_reduced = np.dot(x-pca.mean_, pca.components_.T) # transform\n",
    "data_original = np.dot(data_reduced, pca.components_)+ pca.mean_ # inverse_transform\n",
    "# print(data_original-x)  #reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['is_attack']\n",
    "\n",
    "x_train = x\n",
    "benign_flows['is_attack']= 0\n",
    "y_train = benign_flows.loc[:, labels].values\n",
    "\n",
    "x_test = mixed_flows.loc[:, features].values\n",
    "y_test = mixed_flows.loc[:, labels].values    \n",
    "\n",
    "# normalizing\n",
    "#x_train = preprocessing.normalize(x_train, axis=0)\n",
    "x_test = preprocessing.normalize(x_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pca = pca.transform(x_train_flat)\n",
    "test_pca = pca.transform(x_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary libraries to run the deep learning model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constant declaration\n",
    "batch_size = 128\n",
    "num_classes  = 2\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(top_k_component,)))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 14s 34ms/step - loss: 0.0491 - accuracy: 0.9850 - val_loss: 363790848.0000 - val_accuracy: 0.3886\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 363790848.0000 - val_accuracy: 0.3886\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 363790848.0000 - val_accuracy: 0.3886\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 363790848.0000 - val_accuracy: 0.3886\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 363790848.0000 - val_accuracy: 0.3886\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 13s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 363790848.0000 - val_accuracy: 0.3886\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 363790848.0000 - val_accuracy: 0.3886\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 13s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 363790848.0000 - val_accuracy: 0.3886\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 363790848.0000 - val_accuracy: 0.3886\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 13s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 363790848.0000 - val_accuracy: 0.3886\n"
     ]
    }
   ],
   "source": [
    "# compiling and training the model with the reduced dimension\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_pca, y_train,batch_size=batch_size,epochs=epochs,verbose=1,\n",
    "                    validation_data=(test_pca, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 0.0154 - accuracy: 0.9883 - val_loss: 5.2240 - val_accuracy: 0.3886\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.2240 - val_accuracy: 0.3886\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.2240 - val_accuracy: 0.3886\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 13s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.2240 - val_accuracy: 0.3886\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.2240 - val_accuracy: 0.3886\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.2240 - val_accuracy: 0.3886\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.2240 - val_accuracy: 0.3886\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.2240 - val_accuracy: 0.3886\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 13s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.2240 - val_accuracy: 0.3886\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.2240 - val_accuracy: 0.3886\n"
     ]
    }
   ],
   "source": [
    "# checking how the model works with all the features\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(dim,)))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
